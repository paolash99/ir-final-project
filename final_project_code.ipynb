{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d887270-8dca-42c7-93b3-1bd076a45383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Paola/ir_env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import html\n",
    "import numpy as np\n",
    "from math import log\n",
    "from collections import Counter\n",
    "import math\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "\n",
    "from whoosh.fields import Schema, TEXT, ID, NUMERIC, BOOLEAN\n",
    "from whoosh.index import create_in, open_dir\n",
    "from whoosh.analysis import StandardAnalyzer\n",
    "from whoosh.qparser import QueryParser\n",
    "from whoosh.qparser import MultifieldParser\n",
    "from whoosh.scoring import BM25F, WeightingModel, WeightLengthScorer\n",
    "from whoosh.searching import Searcher\n",
    "from whoosh.qparser import OrGroup\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a2602-4a07-4906-a3d9-0666148c9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Index\n",
    "# === Inputs ===\n",
    "inputs = [\n",
    "    \"/Users/Paola/Desktop/IR/softwareengineering.stackexchange.com\",\n",
    "    \"/Users/Paola/Desktop/IR/cseducators.stackexchange.com/Posts.xml\",\n",
    "    \"/Users/Paola/Desktop/IR/cstheory.stackexchange.com/Posts.xml\",\n",
    "    \"/Users/Paola/Desktop/IR/cs.stackexchange.com/Posts.xml\",\n",
    "    \"/Users/Paola/Desktop/IR/ai.stackexchange.com/Posts.xml\",\n",
    "    \"/Users/Paola/Desktop/IR/datascience.stackexchange.com/Posts.xml\"\n",
    "]\n",
    "\n",
    "# === Resolve valid XML files ===\n",
    "xml_files = []\n",
    "for path in inputs:\n",
    "    if os.path.isdir(path):\n",
    "        candidate = os.path.join(path, \"Posts.xml\")\n",
    "        if os.path.exists(candidate):\n",
    "            xml_files.append(candidate)\n",
    "    elif path.lower().endswith(\".xml\") and os.path.exists(path):\n",
    "        xml_files.append(path)\n",
    "\n",
    "print(\"Indexing from these XML files:\")\n",
    "for f in xml_files:\n",
    "    print(\" \", f)\n",
    "\n",
    "# === HTML tag stripper ===\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "def clean_html(raw_html):\n",
    "    return TAG_RE.sub('', html.unescape(raw_html))\n",
    "\n",
    "# === Document aggregator ===\n",
    "aggregated_docs = {}\n",
    "for xml_file in xml_files:\n",
    "    site_name = os.path.basename(os.path.dirname(xml_file)) if xml_file.endswith(\"Posts.xml\") else os.path.basename(xml_file).replace(\".xml\", \"\")\n",
    "    print(f\"Reading posts from {site_name}...\")\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    for row in root.findall('row'):\n",
    "        pid = row.attrib.get('Id')\n",
    "        if not pid:\n",
    "            continue\n",
    "        post_type = row.attrib.get('PostTypeId')\n",
    "        unique_id = f\"{site_name}:{pid}\"\n",
    "        if post_type == \"1\":  # Question\n",
    "            title = clean_html(row.attrib.get('Title', \"\"))\n",
    "            body = clean_html(row.attrib.get('Body', \"\"))\n",
    "            raw_tags = row.attrib.get('Tags', \"\")\n",
    "            tag_list = raw_tags.strip(\"|\").split(\"|\") if raw_tags else []\n",
    "            tags = \",\".join(tag_list)\n",
    "            aggregated_docs[unique_id] = {\n",
    "                'title': title,\n",
    "                'body': body,\n",
    "                'tags': tags,\n",
    "                'site': site_name,\n",
    "                'original_id': pid\n",
    "            }\n",
    "        elif post_type == \"2\":  # Answer\n",
    "            parent_pid = row.attrib.get('ParentId')\n",
    "            if parent_pid:\n",
    "                parent_uid = f\"{site_name}:{parent_pid}\"\n",
    "                answer_body = clean_html(row.attrib.get('Body', \"\"))\n",
    "                if parent_uid in aggregated_docs:\n",
    "                    aggregated_docs[parent_uid]['body'] += \"\\n\\n[Answer]: \" + answer_body\n",
    "\n",
    "# === Create Whoosh index ===\n",
    "schema = Schema(\n",
    "    post_id=ID(stored=True, unique=True),\n",
    "    title=TEXT(stored=True, analyzer=StandardAnalyzer()),\n",
    "    body=TEXT(stored=True, analyzer=StandardAnalyzer()),\n",
    "    tags=TEXT(stored=True, analyzer=StandardAnalyzer())\n",
    ")\n",
    "\n",
    "if not os.path.exists(\"indexdir\"):\n",
    "    os.mkdir(\"indexdir\")\n",
    "ix = create_in(\"indexdir\", schema)\n",
    "writer = ix.writer()\n",
    "print(f\"Adding {len(aggregated_docs)} documents to the index…\")\n",
    "for qid, doc in aggregated_docs.items():\n",
    "    writer.add_document(\n",
    "        post_id=qid,\n",
    "        title=doc['title'],\n",
    "        body=doc['body'],\n",
    "        tags=doc['tags']\n",
    "    )\n",
    "writer.commit()\n",
    "print(\"Indexing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7abd3f-bb63-44db-9170-d4ac2da4880a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BM25\n",
    "def tokenize_query(query_str):\n",
    "    analyzer = StandardAnalyzer()\n",
    "    return [token.text for token in analyzer(query_str)]\n",
    " \n",
    "def search_with_bm25(query_text, title_boost=1.0, top_k=5):\n",
    "    \"\"\"\n",
    "    Search using BM25 with field boosting\n",
    "    \"\"\"\n",
    "    ix = open_dir(\"indexdir\")\n",
    "    \n",
    "    # Tokenize query\n",
    "    tokens = tokenize_query(query_text)\n",
    "    print(\"Tokenized query (BM25):\", tokens)\n",
    "    query_text = \" \".join(tokens)  # Replace original query with tokenized version\n",
    "\n",
    "    # Configure BM25F with field boosting\n",
    "    bm25 = BM25F(B=0.75, title_B=0.5, body_B=0.5, title_boost=0.5, body_boost=0.5)\n",
    "    \n",
    "    # Create parser\n",
    "    parser = MultifieldParser([\"title\", \"body\"], ix.schema, group=OrGroup)\n",
    "    \n",
    "    # Parse and search\n",
    "    q = parser.parse(query_text)\n",
    "    with ix.searcher(weighting=bm25) as searcher:\n",
    "        results = searcher.search(q, limit=top_k)\n",
    "        print(f\"\\n=== BM25 Search Results (title_boost={title_boost}) ===\")\n",
    "        for i, hit in enumerate(results):\n",
    "            print(f\"{i+1}. [{hit['post_id']}] {hit['title']} (Score: {hit.score:.4f})\")\n",
    "\n",
    "# === Run search with example query ===\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"How do I detect a cycle in a graph?\"\n",
    "\n",
    "    # Search with BM25\n",
    "    search_with_bm25(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7288e790-2bcb-4660-af6f-3dd5306ecb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLM\n",
    "def tokenize(text):\n",
    "    analyzer = StandardAnalyzer()\n",
    "    return [token.text for token in analyzer(text)]\n",
    "\n",
    "def compute_dirichlet_scores_for_field(searcher, query_terms, field, mu, weight):\n",
    "    total_terms = searcher.field_length(field)\n",
    "    doc_scores = defaultdict(float)\n",
    "    doc_lengths = {\n",
    "        docnum: searcher.doc_field_length(docnum, field)\n",
    "        for docnum in range(searcher.doc_count_all())\n",
    "    }\n",
    "\n",
    "    # Compute P(q_i | C_f)\n",
    "    term_collection_probs = {}\n",
    "    for term in query_terms:\n",
    "        cf = searcher.frequency(field, term)\n",
    "        if cf > 0:\n",
    "            term_collection_probs[term] = cf / total_terms\n",
    "\n",
    "    for term, p_coll in term_collection_probs.items():\n",
    "        matcher = searcher.postings(field, term)\n",
    "        seen_docs = set()\n",
    "\n",
    "        if matcher.is_active():\n",
    "            while matcher.is_active():\n",
    "                docnum = matcher.id()\n",
    "                tf = matcher.value_as(\"frequency\")\n",
    "                doc_len = doc_lengths.get(docnum, 0) or 0\n",
    "                score = math.log((tf + mu * p_coll) / (doc_len + mu))\n",
    "                doc_scores[docnum] += weight * score\n",
    "                seen_docs.add(docnum)\n",
    "                matcher.next()\n",
    "\n",
    "        for docnum in doc_lengths.keys():\n",
    "            if docnum not in seen_docs:\n",
    "                doc_len = doc_lengths.get(docnum, 0) or 0\n",
    "                score = math.log((mu * p_coll) / (doc_len + mu))\n",
    "                doc_scores[docnum] += weight * score\n",
    "\n",
    "    return doc_scores\n",
    "\n",
    "def query_likelihood_with_dirichlet_multifield(query, k=10, mu=2000, field_weights={\"body\": 0.5, \"title\": 0.8}):\n",
    "    ix = open_dir(\"indexdir\")\n",
    "    query_terms = tokenize(query)\n",
    "    combined_scores = defaultdict(float)\n",
    "\n",
    "    with ix.searcher() as searcher:\n",
    "        for field, weight in field_weights.items():\n",
    "            field_scores = compute_dirichlet_scores_for_field(searcher, query_terms, field, mu, weight)\n",
    "            for docnum, score in field_scores.items():\n",
    "                combined_scores[docnum] += score\n",
    "\n",
    "        top_k = heapq.nlargest(k, combined_scores.items(), key=lambda x: x[1])\n",
    "        return [(searcher.stored_fields(docnum), score) for docnum, score in top_k]\n",
    "\n",
    "results = query_likelihood_with_dirichlet_multifield(\"How to load a large json file in python?\", k=5, mu=2000, field_weights={\"body\": 0.3, \"title\": 0.7})\n",
    "for i, (doc, score) in enumerate(results):\n",
    "    print(f\"{i+1}. {doc['post_id']} — {doc['title']} — Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d0c1f33-7e79-495d-9808-88b1e785e66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Paola/ir_env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/Paola/ir_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Embedding-based Reranked Results ===\n",
      "1. cs.stackexchange.com:63255 — Output cycle found by DFS — CosSim: 0.6395\n",
      "cs.stackexchange.com:63255\n",
      "2. cs.stackexchange.com:96918 — Detect non existence of a cycle in a graph using Datalog : SMTLIB Format for Z3 — CosSim: 0.5682\n",
      "cs.stackexchange.com:96918\n",
      "3. cstheory.stackexchange.com:49017 — Detect if a graph has a $k$ cycle in space complexity $O((\\log k)^d)$ for fixed $d \\geq1$ — CosSim: 0.5437\n",
      "cstheory.stackexchange.com:49017\n",
      "4. cs.stackexchange.com:75952 — detecting a cycle in an undirected graph problem is in $RL$ complexity class — CosSim: 0.5363\n",
      "cs.stackexchange.com:75952\n",
      "5. cs.stackexchange.com:75341 — Proving $\\#CYCLE \\in \\#P$ — CosSim: 0.5202\n",
      "cs.stackexchange.com:75341\n"
     ]
    }
   ],
   "source": [
    "# Embedding reranking\n",
    "\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def rerank_with_embeddings(query, candidates, top_k=5):\n",
    "    query_emb = embed_model.encode(query, convert_to_tensor=True)\n",
    "    doc_texts = [doc[\"title\"] + \" \" + doc[\"body\"] for doc, _ in candidates]\n",
    "    doc_embs = embed_model.encode(doc_texts, convert_to_tensor=True)\n",
    "\n",
    "    similarities = util.cos_sim(query_emb, doc_embs)[0]\n",
    "    scored = list(zip(candidates, similarities))\n",
    "    scored.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [(doc, score.item()) for (doc, _), score in scored[:top_k]]\n",
    "    \n",
    "query = \"How do I detect a cycle in a graph?\"\n",
    "qlm_results = query_likelihood_with_dirichlet_multifield(query, k=20, mu=2000, field_weights={\"body\": 0.3, \"title\": 0.7})\n",
    "reranked = rerank_with_embeddings(query, qlm_results, top_k=5)\n",
    "\n",
    "print(\"=== Embedding-based Reranked Results ===\")\n",
    "for i, (doc, score) in enumerate(reranked):\n",
    "    print(f\"{i+1}. {doc['post_id']} — {doc['title']} — CosSim: {score:.4f}\")\n",
    "    # print(doc['body'])\n",
    "    print(doc['post_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "bd478e5a-3af3-4c6e-bec1-931d48433361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo relevance feedback\n",
    "\n",
    "def relevance_model_rerank(query_str, fields=[\"body\"], top_k_candidate=10, top_k_final=3, mu=2000):\n",
    "    # Get top-k results with your QLM model\n",
    "    initial_results = query_likelihood_with_dirichlet_multifield(\n",
    "        query=query_str,\n",
    "        k=top_k_candidate,\n",
    "        mu=mu,\n",
    "        field_weights={\"body\": 0.3, \"title\": 0.7}\n",
    "    )\n",
    "\n",
    "    # Separate docs and scores\n",
    "    c_docs = [doc for doc, _ in initial_results]\n",
    "    c_scores = {doc['post_id']: score for doc, score in initial_results}\n",
    "\n",
    "    # Tokenize and collect term stats\n",
    "    analyzer = StandardAnalyzer()\n",
    "    stats = {}\n",
    "    vocab = set()\n",
    "\n",
    "    for doc in c_docs:\n",
    "        combined_text = \" \".join(doc.get(f, \"\") for f in fields)\n",
    "        toks = [t.text for t in analyzer(combined_text)]\n",
    "        cnts = Counter(toks)\n",
    "        total = sum(cnts.values())\n",
    "        stats[doc['post_id']] = {'cnts': cnts, 'tot': total}\n",
    "        vocab.update(cnts)\n",
    "\n",
    "    V = len(vocab)\n",
    "\n",
    "    def p_w_D(ds, w):\n",
    "        return (ds['cnts'].get(w, 0) + 1) / (ds['tot'] + V)\n",
    "\n",
    "    # Build relevance model\n",
    "    W = {}\n",
    "    S = sum(c_scores.values())\n",
    "\n",
    "    for w in vocab:\n",
    "        W[w] = sum(c_scores[d['post_id']] * p_w_D(stats[d['post_id']], w) for d in c_docs) / (S or 1)\n",
    "\n",
    "    # Rerank using RM1\n",
    "    rerank = {}\n",
    "    for doc in c_docs:\n",
    "        score = sum(W[w] * log(p_w_D(stats[doc['post_id']], w)) for w in vocab)\n",
    "        rerank[doc['post_id']] = score\n",
    "\n",
    "    sorted_docs = sorted(c_docs, key=lambda d: rerank[d['post_id']], reverse=True)\n",
    "\n",
    "    # Print and return top-k\n",
    "    print(f\"----- Top {top_k_final} Results Using RM Re-ranking -----\")\n",
    "    for i, doc in enumerate(sorted_docs[:top_k_final], 1):\n",
    "        print(f\"{i}. Post ID: {doc['post_id']}, Title: {doc.get('title', '')}\")\n",
    "        print(f\"   Score: {rerank[doc['post_id']]:.4f}\")\n",
    "        print(f\"   Body: {doc.get('body', '')}\")\n",
    "        # print(doc['post_id'])\n",
    "\n",
    "    return sorted_docs[:top_k_final]\n",
    "\n",
    "relevance_model_rerank(\n",
    "    query_str=\"What’s the difference between Big-O, Big-Theta, and Big-Omega?\",\n",
    "    fields=[\"body\", \"title\"],\n",
    "    top_k_candidate=5,\n",
    "    top_k_final=5,\n",
    "    mu=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1499d93-1d21-4353-b5e3-bfbb1c27c813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for accepted answers...\n",
      "Indexing filtered and boosted questions only...\n",
      "Adding 145818 documents to the index…\n",
      "Indexing complete!\n"
     ]
    }
   ],
   "source": [
    "# Index with meta data\n",
    "\n",
    "# === Inputs ===\n",
    "input_dir = \"/Users/Paola/Desktop/IR\"\n",
    "site_dirs = [\n",
    "    \"softwareengineering.stackexchange.com\",\n",
    "    \"cseducators.stackexchange.com\",\n",
    "    \"cstheory.stackexchange.com\",\n",
    "    \"cs.stackexchange.com\",\n",
    "    \"ai.stackexchange.com\",\n",
    "    \"datascience.stackexchange.com\"\n",
    "]\n",
    "\n",
    "# === HTML tag stripper ===\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "def clean_html(raw_html):\n",
    "    return TAG_RE.sub('', html.unescape(raw_html))\n",
    "\n",
    "# === Read accepted answer IDs for each question ===\n",
    "accepted_answers = {}\n",
    "print(\"Scanning for accepted answers...\")\n",
    "for site in site_dirs:\n",
    "    path = os.path.join(input_dir, site, \"Posts.xml\")\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    for row in root.findall('row'):\n",
    "        if row.attrib.get('PostTypeId') == \"1\":  # Question\n",
    "            aid = row.attrib.get('AcceptedAnswerId')\n",
    "            if aid:\n",
    "                accepted_answers[f\"{site}:{aid}\"] = True\n",
    "\n",
    "# === Document aggregator with filters and metadata ===\n",
    "aggregated_docs = {}\n",
    "print(\"Indexing filtered and boosted questions only...\")\n",
    "for site in site_dirs:\n",
    "    path = os.path.join(input_dir, site, \"Posts.xml\")\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    for row in root.findall('row'):\n",
    "        pid = row.attrib.get('Id')\n",
    "        if not pid:\n",
    "            continue\n",
    "        post_type = row.attrib.get('PostTypeId')\n",
    "        unique_id = f\"{site}:{pid}\"\n",
    "\n",
    "        if post_type == \"1\":  # Question\n",
    "            answer_count = int(row.attrib.get(\"AnswerCount\", \"0\"))\n",
    "            if answer_count == 0:\n",
    "                continue  # Filter: skip questions with no answers\n",
    "\n",
    "            title = clean_html(row.attrib.get('Title', \"\"))\n",
    "            body = clean_html(row.attrib.get('Body', \"\"))\n",
    "            raw_tags = row.attrib.get('Tags', \"\")\n",
    "            tag_list = raw_tags.strip(\"|\").split(\"|\") if raw_tags else []\n",
    "            tags = \",\".join(tag_list)\n",
    "            score = int(row.attrib.get(\"Score\", \"0\"))\n",
    "            has_accepted = (\n",
    "                row.attrib.get(\"AcceptedAnswerId\") \n",
    "                and f\"{site}:{row.attrib['AcceptedAnswerId']}\" in accepted_answers\n",
    "            )\n",
    "\n",
    "            aggregated_docs[unique_id] = {\n",
    "                'title': title,\n",
    "                'body': body,\n",
    "                'tags': tags,\n",
    "                'score': score,\n",
    "                'answer_count': answer_count,\n",
    "                'has_accepted': has_accepted,\n",
    "            }\n",
    "        elif post_type == \"2\":  # Answer\n",
    "            parent_pid = row.attrib.get('ParentId')\n",
    "            if parent_pid:\n",
    "                parent_uid = f\"{site}:{parent_pid}\"\n",
    "                answer_body = clean_html(row.attrib.get('Body', \"\"))\n",
    "                if parent_uid in aggregated_docs:\n",
    "                    aggregated_docs[parent_uid]['body'] += \"\\n\\n[Answer]: \" + answer_body\n",
    "\n",
    "# === Create Whoosh index with metadata ===\n",
    "schema = Schema(\n",
    "    post_id=ID(stored=True, unique=True),\n",
    "    title=TEXT(stored=True, analyzer=StandardAnalyzer()),\n",
    "    body=TEXT(stored=True, analyzer=StandardAnalyzer()),\n",
    "    tags=TEXT(stored=True, analyzer=StandardAnalyzer()),\n",
    "    score=NUMERIC(stored=True),\n",
    "    answer_count=NUMERIC(stored=True),\n",
    "    has_accepted=BOOLEAN(stored=True)\n",
    ")\n",
    "\n",
    "if not os.path.exists(\"indexdir\"):\n",
    "    os.mkdir(\"indexdir\")\n",
    "\n",
    "ix = create_in(\"indexdir\", schema)\n",
    "writer = ix.writer()\n",
    "print(f\"Adding {len(aggregated_docs)} documents to the index…\")\n",
    "for qid, doc in aggregated_docs.items():\n",
    "    writer.add_document(\n",
    "        post_id=qid,\n",
    "        title=doc['title'],\n",
    "        body=doc['body'],\n",
    "        tags=doc['tags'],\n",
    "        score=doc['score'],\n",
    "        answer_count=doc['answer_count'],\n",
    "        has_accepted=doc['has_accepted']\n",
    "    )\n",
    "writer.commit()\n",
    "print(\"Indexing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f750106d-d917-434f-b10d-8aaf1a9cd78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLM with metadata\n",
    "def query_likelihood_with_dirichlet_multifield(query, k=10, mu=2000, field_weights={\"body\": 0.5, \"title\": 0.8},\n",
    "                                               accepted_boost=1.1, answer_boost_scale=0.05):\n",
    "    ix = open_dir(\"indexdir\")\n",
    "    query_terms = tokenize(query)\n",
    "    combined_scores = defaultdict(float)\n",
    "\n",
    "    with ix.searcher() as searcher:\n",
    "        for field, weight in field_weights.items():\n",
    "            field_scores = compute_dirichlet_scores_for_field(searcher, query_terms, field, mu, weight)\n",
    "            for docnum, score in field_scores.items():\n",
    "                combined_scores[docnum] += score\n",
    "\n",
    "        # Apply boosts\n",
    "        boosted_scores = {}\n",
    "        for docnum, score in combined_scores.items():\n",
    "            doc = searcher.stored_fields(docnum)\n",
    "            boost = 1.0\n",
    "            if doc.get(\"has_accepted\") == \"yes\":\n",
    "                boost *= accepted_boost\n",
    "            answer_count = int(doc.get(\"answer_count\", 0))\n",
    "            boost *= (1 + answer_boost_scale * answer_count)\n",
    "            boosted_scores[docnum] = score * boost\n",
    "\n",
    "        top_k = heapq.nlargest(k, boosted_scores.items(), key=lambda x: x[1])\n",
    "        return [(searcher.stored_fields(docnum), score) for docnum, score in top_k]\n",
    "\n",
    "query = \"How do I efficiently load a large json file in Python?\"\n",
    "qlm_results = query_likelihood_with_dirichlet_multifield(\n",
    "    query,\n",
    "    k=20,\n",
    "    mu=2000,\n",
    "    field_weights={\"body\": 0.3, \"title\": 0.7},\n",
    "    accepted_boost=1.15,\n",
    "    answer_boost_scale=0.03\n",
    ")\n",
    "reranked = rerank_with_embeddings(query, qlm_results, top_k=10)\n",
    "\n",
    "for i, (doc, score) in enumerate(reranked):\n",
    "    print(f\"{i+1}. {doc['post_id']} — {doc['title']} — CosSim: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19dd6625-2167-4c7f-ae7f-108ed8948066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo ranking SVM\n",
    "def pseudo_relevance_training(queries, k=6, mu=2000, field_weights={\"body\": 0.3, \"title\": 0.7},\n",
    "                               accepted_boost=1.15, answer_boost_scale=0.03,\n",
    "                               return_docs=False):\n",
    "    X, y = [], []\n",
    "    docs_out = []  # to store documents if return_docs is True\n",
    "\n",
    "    for query in queries:\n",
    "        top_docs = query_likelihood_with_dirichlet_multifield(\n",
    "            query=query,\n",
    "            k=k,\n",
    "            mu=mu,\n",
    "            field_weights=field_weights,\n",
    "            accepted_boost=accepted_boost,\n",
    "            answer_boost_scale=answer_boost_scale\n",
    "        )\n",
    "\n",
    "        midpoint = len(top_docs) // 2\n",
    "        pseudo_labels = [1 if i < midpoint else 0 for i in range(len(top_docs))]\n",
    "\n",
    "        query_emb = embed_model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "        for i, ((doc, qlm_score), label) in enumerate(zip(top_docs, pseudo_labels)):\n",
    "            doc_text = doc[\"title\"] + \" \" + doc[\"body\"]\n",
    "            doc_emb = embed_model.encode(doc_text, convert_to_tensor=True)\n",
    "            emb_sim = util.cos_sim(query_emb, doc_emb).item()\n",
    "\n",
    "            meta_boost = (\n",
    "                (1.0 if doc.get(\"has_accepted\") else 0.0)\n",
    "                + log(1 + doc.get(\"answer_count\", 0)) * answer_boost_scale\n",
    "            )\n",
    "\n",
    "            X.append([qlm_score, emb_sim, meta_boost])\n",
    "            y.append(label)\n",
    "            if return_docs:\n",
    "                docs_out.append(doc)\n",
    "\n",
    "    if return_docs:\n",
    "        return np.array(X), docs_out\n",
    "    else:\n",
    "        return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef72fc39-512b-4289-8611-a0c502bdd4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"How do I efficiently load a large json file in Python?\",\n",
    "    \"What’s the difference between breadth-first search and depth-first search?\",\n",
    "    \"What are hash maps and how do they work?\",\n",
    "    \"How does memoization improve recursive algorithms?\",\n",
    "    \"How does garbage collection work in Java?\",\n",
    "    \"What’s the difference between static and dynamic typing?\",\n",
    "    \"What is a memory leak and how can I detect it?\",\n",
    "    \"How does Python manage memory?\",\n",
    "    \"When should I use a stack over a queue?\",\n",
    "    \"How does a binary search algorithm work?\",\n",
    "    \"How do I resolve circular import errors in Python?\",\n",
    "    \"What is the difference between process and thread?\",\n",
    "    \"How does a priority queue work internally?\",\n",
    "    \"What is the best way to handle exceptions in Python?\",\n",
    "    \"What is the difference between synchronous and asynchronous programming?\",\n",
    "    \"How do I serialize and deserialize a Python object?\",\n",
    "    \"What’s the difference between REST and GraphQL?\",\n",
    "    \"What is tail recursion and why is it useful?\",\n",
    "    \"How do I avoid race conditions in multithreading?\",\n",
    "    \"What are the advantages of functional programming?\",\n",
    "    \"How does version control with Git work?\",\n",
    "    \"What is a deadlock and how can it be prevented?\",\n",
    "    \"How does a Trie data structure work?\",\n",
    "    \"What is the difference between TCP and UDP?\",\n",
    "    \"How does dynamic programming differ from greedy algorithms?\",\n",
    "    \"What are callbacks and how are they used in JavaScript?\",\n",
    "    \"How can I optimize database queries for performance?\",\n",
    "    \"What is a state machine and where is it used?\",\n",
    "    \"How do I implement a stack using queues?\",\n",
    "    \"What are lambda functions in Python?\",\n",
    "    \"What is the difference between shallow and deep copy in Python?\",\n",
    "    \"How do I handle large datasets in pandas?\",\n",
    "    \"What is the difference between compile-time and runtime errors?\",\n",
    "    \"How can I improve the time complexity of my code?\",\n",
    "    \"What is object-oriented programming and how does it differ from procedural?\",\n",
    "    \"What are the differences between interfaces and abstract classes in Java?\",\n",
    "    \"How does inheritance work in Python?\",\n",
    "    \"How does the call stack work in recursion?\",\n",
    "    \"What is the purpose of the virtual keyword in C++?\",\n",
    "    \"What is dependency injection and why is it used?\",\n",
    "    \"How do I implement caching in Python for faster lookups?\",\n",
    "    \"How do I implement a queue using two stacks?\",\n",
    "    \"What is the difference between synchronous and asynchronous calls?\",\n",
    "    \"How can I optimize a SQL query that uses multiple joins?\",\n",
    "    \"How do I detect memory leaks in a Java application?\",\n",
    "    \"How do I merge two sorted arrays in C++?\",\n",
    "    \"Why does using global variables cause issues in multithreaded programs?\",\n",
    "    \"How do I convert a JSON file into a Python dictionary?\",\n",
    "    \"What are the trade-offs between depth-first and breadth-first traversal?\",\n",
    "    \"How do I fix a segmentation fault in C?\",\n",
    "    \"What causes a stack overflow error in recursive functions?\",\n",
    "    \"How does memoization improve performance?\",\n",
    "    \"Why is quicksort faster than bubble sort in practice?\",\n",
    "    \"How can I write a tail-recursive function in Python?\",\n",
    "    \"What’s the time complexity of inserting into a binary search tree?\"\n",
    "]\n",
    "\n",
    "X, y = pseudo_relevance_training(queries)\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='linear', probability=True))\n",
    "])\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d8394-8497-432a-b775-9f53b332293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your test queries\n",
    "test_queries = [\n",
    "    \"How do I detect a cycle in a graph?\",\n",
    "]\n",
    "\n",
    "# Run pseudo relevance feature extraction\n",
    "X_test, docs_test = pseudo_relevance_training(test_queries, return_docs=True)\n",
    "\n",
    "# Predict scores for each doc using your trained model\n",
    "scores = model.decision_function(X_test)  # shape = (num_docs,)\n",
    "\n",
    "# Group scores and docs per query\n",
    "docs_per_query = 5\n",
    "for i, query in enumerate(test_queries):\n",
    "    start = i * docs_per_query\n",
    "    end = start + docs_per_query\n",
    "\n",
    "    query_scores = scores[start:end]\n",
    "    query_docs = docs_test[start:end]\n",
    "\n",
    "    # Sort by score\n",
    "    ranked = sorted(zip(query_docs, query_scores), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"Top 5 ranked documents:\")\n",
    "    for rank, (doc, score) in enumerate(ranked, 1):\n",
    "        print(f\"{rank}. {doc['post_id']} — {doc['title']} — Score: {score:.4f}\")\n",
    "        # print(doc['body'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
